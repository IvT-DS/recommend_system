{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_urls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 271/271 [03:44<00:00,  1.21it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(1, 272)):\n",
    "    if i == 1:\n",
    "        end = '/'\n",
    "    else:\n",
    "        end = f'&page={i}'\n",
    "    link = f'https://kino.mail.ru/series/all/?order=rate_count&year=1999&year=2024{end}'\n",
    "    content = requests.get(link).content\n",
    "    soup = BeautifulSoup(content, 'lxml')\n",
    "    series = soup.find_all(class_='link link_inline link-holder link-holder_itemevent link-holder_itemevent_small')\n",
    "\n",
    "    for item in series:\n",
    "        item_page_url = item.get('href')\n",
    "        items_urls.append('https://kino.mail.ru' + item_page_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = pd.DataFrame({'url':items_urls})\n",
    "urls.to_csv('urls_mail_ru.csv')\n",
    "\n",
    "items_urls = items_urls[:10000]\n",
    "\n",
    "len(items_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://kino.mail.ru/series_756333_velikolepnii_vek/'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_urls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1, l2, l3, l4 = items_urls[:2500], items_urls[2500:5000], items_urls[5000:7500], items_urls[7500:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "l5 = items_urls[2000:2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 77/2500 [02:37<14:47:09, 21.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ссылка номер: 2576, ссылка: https://kino.mail.ru/series_769682_virtuozi/, ошибка: HTTPSConnectionPool(host='kino.mail.ru', port=443): Max retries exceeded with url: /series_769682_virtuozi/ (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1006)')))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 89/2500 [02:46<39:57,  1.01it/s]   "
     ]
    }
   ],
   "source": [
    "titles = []\n",
    "sources = []\n",
    "descriptions = []\n",
    "ganres = []\n",
    "years = []\n",
    "posters = []\n",
    "casts = []\n",
    "ratings = []\n",
    "s = 1\n",
    "\n",
    "for url in tqdm(l2):\n",
    "    try:\n",
    "        text = requests.get(url).text\n",
    "        soup = BeautifulSoup(text, 'lxml')\n",
    "        try:\n",
    "            title = soup.find('h1', class_='text text_bold_giant color_white').text\n",
    "        \n",
    "            titles.append(title[:title.find(' (сери')])\n",
    "        except:\n",
    "            print('маслина')\n",
    "            titles.append(None)\n",
    "        # тянем постер\n",
    "        try:\n",
    "            picture_url = soup.find('meta', itemprop='image')['content']\n",
    "            posters.append(picture_url)\n",
    "        except:\n",
    "            posters.append(None)\n",
    "        # тянем жанры\n",
    "        try:\n",
    "            ganre = soup.find_all('span', class_='badge__text')\n",
    "            helper = []\n",
    "            for i in ganre:\n",
    "                helper.append(i.text)\n",
    "            ganres.append(helper)\n",
    "        except:\n",
    "            ganres.append(None)\n",
    "        # тянем cast\n",
    "        try:\n",
    "            cast = soup.find_all('span', class_='p-truncate__inner js-toggle__truncate-inner')\n",
    "            a = []\n",
    "            for act in cast:\n",
    "                a.append(act.text)\n",
    "            casts.append(a[1:4])\n",
    "        except:\n",
    "            casts.append(None)\n",
    "        try:\n",
    "            description = soup.find('div', class_='text text_inline text_light_medium text_fixed valign_baseline p-movie-info__description-text').text\n",
    "            descriptions.append(description.replace('\\xa0', ' '))\n",
    "        except:\n",
    "            descriptions.append(None)\n",
    "        # год\n",
    "        try:\n",
    "            year = soup.find('span', class_='nowrap').text\n",
    "            years.append(year.split()[:3])\n",
    "        except:\n",
    "            years.append(None)\n",
    "        # imdb\n",
    "        try:\n",
    "            rating = float(soup.find('span', class_='text text_bold_huge text_fixed').text)\n",
    "            ratings.append(rating)\n",
    "        except:\n",
    "            ratings.append(None)\n",
    "\n",
    "        sources.append(url)\n",
    "\n",
    "        if (len(sources) % 500 == 0) or (l2[-1] == url):\n",
    "            data = pd.DataFrame({'url':sources,\n",
    "                                'poster':posters,\n",
    "                                'title':titles,\n",
    "                                'ganres':ganres,\n",
    "                                'description':descriptions,\n",
    "                                'year':years,\n",
    "                                'rating':ratings,\n",
    "                                'cast':casts})\n",
    "            print(f'{len(data)} saved')\n",
    "\n",
    "            name = f'l2/data_{s}.csv'\n",
    "\n",
    "            data.to_csv(name)\n",
    "\n",
    "            s += 1\n",
    "            titles = []\n",
    "            sources = []\n",
    "            descriptions = []\n",
    "            ganres = []\n",
    "            years = []\n",
    "            posters = []\n",
    "            casts = []\n",
    "            ratings = []\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"ссылка номер: {items_urls.index(url)}, ссылка: {url}, ошибка: {e}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "499"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx = [202, 2390, 2009]\n",
    "urls_false = []\n",
    "for ind in indx:\n",
    "    urls_false.append(items_urls[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:02<00:00,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def info_get(urls: str):\n",
    "\n",
    "    titles = []\n",
    "    sources = []\n",
    "    descriptions = []\n",
    "    ganres = []\n",
    "    years = []\n",
    "    posters = []\n",
    "    casts = []\n",
    "    ratings = []\n",
    "\n",
    "    for url in tqdm(urls):\n",
    "        try:\n",
    "            text = requests.get(url).text\n",
    "            soup = BeautifulSoup(text, \"lxml\")\n",
    "            try:\n",
    "                title = soup.find(\"h1\", class_=\"text text_bold_giant color_white\").text\n",
    "\n",
    "                titles.append(title[: title.find(\" (сери\")])\n",
    "            except:\n",
    "                print(\"маслина\")\n",
    "                titles.append(None)\n",
    "            # тянем постер\n",
    "            try:\n",
    "                picture_url = soup.find(\"meta\", itemprop=\"image\")[\"content\"]\n",
    "                posters.append(picture_url)\n",
    "            except:\n",
    "                posters.append(None)\n",
    "            # тянем жанры\n",
    "            try:\n",
    "                ganre = soup.find_all(\"span\", class_=\"badge__text\")\n",
    "                helper = []\n",
    "                for i in ganre:\n",
    "                    helper.append(i.text)\n",
    "                ganres.append(helper)\n",
    "            except:\n",
    "                ganres.append(None)\n",
    "            # тянем cast\n",
    "            try:\n",
    "                cast = soup.find_all(\n",
    "                    \"span\", class_=\"p-truncate__inner js-toggle__truncate-inner\"\n",
    "                )\n",
    "                a = []\n",
    "                for act in cast:\n",
    "                    a.append(act.text)\n",
    "                casts.append(a[1:4])\n",
    "            except:\n",
    "                casts.append(None)\n",
    "            # тянем описание\n",
    "            try:\n",
    "                description = soup.find(\n",
    "                    \"div\",\n",
    "                    class_=\"text text_inline text_light_medium text_fixed valign_baseline p-movie-info__description-text\",\n",
    "                ).text\n",
    "                descriptions.append(description.replace(\"\\xa0\", \" \"))\n",
    "            except:\n",
    "                descriptions.append(None)\n",
    "            # год\n",
    "            try:\n",
    "                year = soup.find(\"span\", class_=\"nowrap\").text\n",
    "                years.append(year.split()[:3])\n",
    "            except:\n",
    "                years.append(None)\n",
    "            # imdb\n",
    "            try:\n",
    "                rating = float(\n",
    "                    soup.find(\"span\", class_=\"text text_bold_huge text_fixed\").text\n",
    "                )\n",
    "                ratings.append(rating)\n",
    "            except:\n",
    "                ratings.append(None)\n",
    "\n",
    "            sources.append(url)\n",
    "\n",
    "            if len(sources) == len(urls):\n",
    "                data = pd.DataFrame(\n",
    "                    {\n",
    "                        \"url\": sources,\n",
    "                        \"poster\": posters,\n",
    "                        \"title\": titles,\n",
    "                        \"ganres\": ganres,\n",
    "                        \"description\": descriptions,\n",
    "                        \"year\": years,\n",
    "                        \"rating\": ratings,\n",
    "                        \"cast\": casts,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                print(f\"{len(data)} saved\")\n",
    "                name = f\"l1/data_{666}.csv\"\n",
    "\n",
    "                data.to_csv(name)\n",
    "\n",
    "                titles = []\n",
    "                sources = []\n",
    "                descriptions = []\n",
    "                ganres = []\n",
    "                years = []\n",
    "                posters = []\n",
    "                casts = []\n",
    "                ratings = []\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"ссылка номер: {items_urls.index(url)}, ссылка: {url}, ошибка: {e}\")\n",
    "\n",
    "\n",
    "info_get(urls_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499 saved\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame({'url':sources,\n",
    "                                'poster':posters,\n",
    "                                'title':titles,\n",
    "                                'ganres':ganres,\n",
    "                                'description':descriptions,\n",
    "                                'year':years,\n",
    "                                'rating':ratings,\n",
    "                                'cast':casts})\n",
    "print(f'{len(data)} saved')\n",
    "name = f'l1/data_{5}.csv'\n",
    "\n",
    "data.to_csv(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ml1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2500\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "l1[2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(l1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
